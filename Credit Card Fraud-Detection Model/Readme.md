The main focus of the project is to try and improve on the previous fraud detection models comparing various sampling techniques, classifiers, and performance metrics. We used a dataset generated by the transactions made by European cardholders in September 2013. All the transactions were made in two days, so the dataset is highly skewed. To solve this issue, we used various sampling methods on the dataset since machine learning models would learn better from a balanced dataset. Here we also see why accuracy is not a good metric for our problem and explore other metrics that are widely used for dealing with unbalanced data such as precision, recall & AUC-PR.
For this research, we carried out experiments using ensemble learning models like bagging, boosting, voting, and artificial neural networks along with oversampling (SMOTE) and a combination of oversampling and undersampling (ROS+RUS) to learn the dataset and identify the best learning model among them. More specifically, we used:
(1) Random Forest Classifier with 100 estimators (Decision trees) as an instance of Bagging that uses bootstrap samples of the training dataset.
(2) XG Boost Classifier with a maximum depth of 3 for each tree as an instance of Boosting.
(3) Combination of base models such as Logistic Regression (with L2 penalty), Decision Tree Classifier, Gaussian Na√Øve Bayes, and K Nearest Neighbors with K=5 neighbors as an
instance of Voting Classifier.
(4) Multi-Layer Perceptron (MLP) as an instance of ANN that consists of two hidden layers
of size (100, 50), which uses Cross Entropy Loss and ReLu activation functions.
