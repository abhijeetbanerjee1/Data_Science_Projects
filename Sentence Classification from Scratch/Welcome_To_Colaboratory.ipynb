{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlJr7BY7PwgF",
        "outputId": "32688ce5-5b76-4744-9d90-033dbda4c044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwtCoMp2P9Iq",
        "outputId": "35cb4e19-8f90-4175-9be7-82a1a03eb92c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7lhuN4jP-Gs",
        "outputId": "1ea9c021-5f7b-4a0a-8576-f2a7dfd59b1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found device: Tesla T4, n_gpu: 1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Confirm that the GPU is detected\n",
        "\n",
        "assert torch.cuda.is_available()\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = torch.cuda.get_device_name()\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n",
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mckBCkk3P_0M",
        "outputId": "8fe88f70-753c-4636-9bc8-773f1554f5c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install -U -q PyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zMakH_OMQCzn"
      },
      "outputs": [],
      "source": [
        "from helpers import tokenize_and_format, flat_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igLwlZdpQy6Z",
        "outputId": "62e7400e-13cb-4295-d5ca-ae88cc096b81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  \"Idadi ya wazee ya Kanada na kiwango cha chini cha kuzaliwa vinasababisha uhaba wa wafanyikazi katika tasnia kuu, na kufanya uhamiaji kuwa chanzo muhimu cha talanta na kazi, kulingana na ripoti ya Bodi ya Mikutano ya Kanada.\"\n",
            "Token IDs: tensor([   101,    107,  29262,  10703,  10549,  11471,  70805,  10549,  12860,\n",
            "         10132,  10879,  24238,  10133,  18939,  89463,  18939,  15694,  75881,\n",
            "         11037,  38973,  23031,  51382,  54112,    189, 100025,  10113,  11471,\n",
            "         11471,  24049,  85382,  28059,  13743,  30853,  11335, 107591,    117,\n",
            "         10132,  15694,  95610,    189,  13196,  10280,  10775,  26979,  62628,\n",
            "         12096,  12361,  31362,  10138,  18939, 100707,  14732,  10132,  82729,\n",
            "           117,  15694,  11945,  11631,  10132,  29956,  37604,  10116,  10549,\n",
            "           102])\n"
          ]
        }
      ],
      "source": [
        "from helpers import tokenize_and_format, flat_accuracy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "df = pd.read_csv('augmented_data.tsv', sep = \"\\t\") #augmented data\n",
        "#df = pd.read_csv('seed.tsv')\n",
        "\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "texts = df.sentence.values\n",
        "labels = df.label_ID.values\n",
        "\n",
        "### tokenize_and_format() is a helper function provided in helpers.py ###\n",
        "input_ids, attention_masks = tokenize_and_format(texts)\n",
        "\n",
        "label_list = []\n",
        "for l in labels:\n",
        "  label_array = np.zeros(len(set(labels)))\n",
        "  label_array[int(l)-1] = 1\n",
        "  label_list.append(label_array)\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(np.array(label_list))\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', texts[0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8dmnOlCxQ1qs"
      },
      "outputs": [],
      "source": [
        "total = len(df)\n",
        "\n",
        "num_train = int(total * .8)\n",
        "num_val = int(total * .1)\n",
        "num_test = total - num_train - num_val\n",
        "\n",
        "# make lists of 3-tuples (already shuffled the dataframe in cell above)\n",
        "\n",
        "train_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_train)]\n",
        "val_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_train, num_val+num_train)]\n",
        "test_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_val + num_train, total)]\n",
        "\n",
        "train_text = [texts[i] for i in range(num_train)]\n",
        "val_text = [texts[i] for i in range(num_train, num_val+num_train)]\n",
        "test_text = [texts[i] for i in range(num_val + num_train, total)]\n",
        "#Use test_text to print sentences in words\n",
        "#print(len(test_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ec524b38bc594ab0a179bf29ef1f174e",
            "5240221b374a47628589d3cdde2988c3",
            "e2fabe4c6911416db1b121db636f9554",
            "6b4ba6c7258c4371b08448c81f0b6806",
            "e880b864a58943aa9450851a587ee20e",
            "e7016fc81f71465c9bec034b92d7c47c",
            "d6b42b4abb8a441a96dc83e73290ee29",
            "7abd44b1bafd4c1eb1be8fd628da4af6",
            "4cef12bd5ed444c380f80d97bf15a68c",
            "879c332a35f64d5588f6810fbb82e07b",
            "0c094979aead45f3acda2595d9a745b6"
          ]
        },
        "id": "EgvaYQHqRFz_",
        "outputId": "a8842193-1457-40f4-9e3f-a825a2faee38"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec524b38bc594ab0a179bf29ef1f174e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=15, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-cased\", # Use the 12-layer English BERT model, with an uncased vocab.\n",
        "    num_labels = 15, # The number of output labels.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CT03LlQRXbw",
        "outputId": "44432e45-feb9-4457-a75c-62b7beb6006a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "optimizer = AdamW(model.parameters(), lr = 5e-5, eps = 1e-8) #with default values of learning rate and epsilon value\n",
        "epochs = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LQwce-AeRN2S"
      },
      "outputs": [],
      "source": [
        "#pred_flat = []\n",
        "#labels_flat = []\n",
        "# function to get validation accuracy\n",
        "def get_validation_performance(val_set):\n",
        "    #global pred_flat\n",
        "    #global labels_flat\n",
        "    # Put the model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "\n",
        "    num_batches = int(len(val_set)/batch_size) + 1\n",
        "\n",
        "    total_correct = 0\n",
        "    total_incorrect = 0\n",
        "    for i in range(num_batches):\n",
        "\n",
        "      end_index = min(batch_size * (i+1), len(val_set))\n",
        "\n",
        "      batch = val_set[i*batch_size:end_index]\n",
        "      \n",
        "      if len(batch) == 0: continue\n",
        "\n",
        "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
        "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
        "      label_tensors = torch.stack([data[2] for data in batch])\n",
        "      \n",
        "      # Move tensors to the GPU\n",
        "      b_input_ids = input_id_tensors.to(device)\n",
        "      b_input_mask = input_mask_tensors.to(device)\n",
        "      b_labels = label_tensors.to(device)\n",
        "        \n",
        "      # Tell pytorch not to bother with constructing the compute graph during\n",
        "      # the forward pass, since this is only needed for backprop (training).\n",
        "      with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        \n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "        \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "        \n",
        "        # Move logits and labels to CPU\n",
        "        logits = (logits).detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "\n",
        "        # Calculate the number of correctly labeled examples in batch\n",
        "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "        labels_flat = np.argmax(label_ids, axis=1).flatten()\n",
        "\n",
        "        num_correct = np.sum(pred_flat == labels_flat)\n",
        "        total_correct += num_correct\n",
        "        \n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"Num of correct predictions =\", total_correct)\n",
        "    avg_val_accuracy = total_correct / len(val_set)\n",
        "    return avg_val_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raJk3c_7RQjn",
        "outputId": "ab5965e3-ea29-47dd-ffd5-edb27fd81411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 25 ========\n",
            "Training...\n",
            "Total loss: 30.812918429289553\n",
            "Num of correct predictions = 193\n",
            "Validation accuracy: 0.21931818181818183\n",
            "\n",
            "======== Epoch 2 / 25 ========\n",
            "Training...\n",
            "Total loss: 21.246055245720587\n",
            "Num of correct predictions = 547\n",
            "Validation accuracy: 0.6215909090909091\n",
            "\n",
            "======== Epoch 3 / 25 ========\n",
            "Training...\n",
            "Total loss: 12.919810804893249\n",
            "Num of correct predictions = 646\n",
            "Validation accuracy: 0.7340909090909091\n",
            "\n",
            "======== Epoch 4 / 25 ========\n",
            "Training...\n",
            "Total loss: 8.243743199601884\n",
            "Num of correct predictions = 710\n",
            "Validation accuracy: 0.8068181818181818\n",
            "\n",
            "======== Epoch 5 / 25 ========\n",
            "Training...\n",
            "Total loss: 5.369958922387679\n",
            "Num of correct predictions = 716\n",
            "Validation accuracy: 0.8136363636363636\n",
            "\n",
            "======== Epoch 6 / 25 ========\n",
            "Training...\n",
            "Total loss: 3.7711706045415334\n",
            "Num of correct predictions = 738\n",
            "Validation accuracy: 0.8386363636363636\n",
            "\n",
            "======== Epoch 7 / 25 ========\n",
            "Training...\n",
            "Total loss: 2.7480368061893388\n",
            "Num of correct predictions = 746\n",
            "Validation accuracy: 0.8477272727272728\n",
            "\n",
            "======== Epoch 8 / 25 ========\n",
            "Training...\n",
            "Total loss: 2.44764524780024\n",
            "Num of correct predictions = 720\n",
            "Validation accuracy: 0.8181818181818182\n",
            "\n",
            "======== Epoch 9 / 25 ========\n",
            "Training...\n",
            "Total loss: 1.922281783098576\n",
            "Num of correct predictions = 732\n",
            "Validation accuracy: 0.8318181818181818\n",
            "\n",
            "======== Epoch 10 / 25 ========\n",
            "Training...\n",
            "Total loss: 1.6780870242290498\n",
            "Num of correct predictions = 741\n",
            "Validation accuracy: 0.8420454545454545\n",
            "\n",
            "======== Epoch 11 / 25 ========\n",
            "Training...\n",
            "Total loss: 1.4768765392347938\n",
            "Num of correct predictions = 740\n",
            "Validation accuracy: 0.8409090909090909\n",
            "\n",
            "======== Epoch 12 / 25 ========\n",
            "Training...\n",
            "Total loss: 1.1844779272851604\n",
            "Num of correct predictions = 770\n",
            "Validation accuracy: 0.875\n",
            "\n",
            "======== Epoch 13 / 25 ========\n",
            "Training...\n",
            "Total loss: 1.0168832419379443\n",
            "Num of correct predictions = 756\n",
            "Validation accuracy: 0.8590909090909091\n",
            "\n",
            "======== Epoch 14 / 25 ========\n",
            "Training...\n",
            "Total loss: 1.1443727008957312\n",
            "Num of correct predictions = 759\n",
            "Validation accuracy: 0.8625\n",
            "\n",
            "======== Epoch 15 / 25 ========\n",
            "Training...\n",
            "Total loss: 1.0478091638495397\n",
            "Num of correct predictions = 757\n",
            "Validation accuracy: 0.8602272727272727\n",
            "\n",
            "======== Epoch 16 / 25 ========\n",
            "Training...\n",
            "Total loss: 0.8463423238023098\n",
            "Num of correct predictions = 758\n",
            "Validation accuracy: 0.8613636363636363\n",
            "\n",
            "======== Epoch 17 / 25 ========\n",
            "Training...\n",
            "Total loss: 0.8084400324860477\n",
            "Num of correct predictions = 735\n",
            "Validation accuracy: 0.8352272727272727\n",
            "\n",
            "======== Epoch 18 / 25 ========\n",
            "Training...\n",
            "Total loss: 0.8798523633608512\n",
            "Num of correct predictions = 763\n",
            "Validation accuracy: 0.8670454545454546\n",
            "\n",
            "======== Epoch 19 / 25 ========\n",
            "Training...\n",
            "Total loss: 0.682652646755408\n",
            "Num of correct predictions = 754\n",
            "Validation accuracy: 0.8568181818181818\n",
            "\n",
            "======== Epoch 20 / 25 ========\n",
            "Training...\n",
            "Total loss: 0.765640588567491\n",
            "Num of correct predictions = 750\n",
            "Validation accuracy: 0.8522727272727273\n",
            "\n",
            "======== Epoch 21 / 25 ========\n",
            "Training...\n",
            "Total loss: 0.8628486100485133\n",
            "Num of correct predictions = 761\n",
            "Validation accuracy: 0.8647727272727272\n",
            "\n",
            "======== Epoch 22 / 25 ========\n",
            "Training...\n",
            "Total loss: 0.6401067418083435\n",
            "Num of correct predictions = 762\n",
            "Validation accuracy: 0.865909090909091\n",
            "\n",
            "======== Epoch 23 / 25 ========\n",
            "Training...\n",
            "Total loss: 0.49151261019174713\n",
            "Num of correct predictions = 758\n",
            "Validation accuracy: 0.8613636363636363\n",
            "\n",
            "======== Epoch 24 / 25 ========\n",
            "Training...\n",
            "Total loss: 0.5505032889321076\n",
            "Num of correct predictions = 745\n",
            "Validation accuracy: 0.8465909090909091\n",
            "\n",
            "======== Epoch 25 / 25 ========\n",
            "Training...\n",
            "Total loss: 0.6898555798822823\n",
            "Num of correct predictions = 751\n",
            "Validation accuracy: 0.8534090909090909\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# training loop\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode.\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    num_batches = int(len(train_set)/batch_size) + 1\n",
        "\n",
        "    for i in range(num_batches):\n",
        "      end_index = min(batch_size * (i+1), len(train_set))\n",
        "\n",
        "      batch = train_set[i*batch_size:end_index]\n",
        "\n",
        "      if len(batch) == 0: continue\n",
        "\n",
        "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
        "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
        "      label_tensors = torch.stack([data[2] for data in batch])\n",
        "\n",
        "      # Move tensors to the GPU\n",
        "      b_input_ids = input_id_tensors.to(device)\n",
        "      b_input_mask = input_mask_tensors.to(device)\n",
        "      b_labels = label_tensors.to(device) \n",
        "\n",
        "      # Perform a forward pass (evaluate the model on this training batch).\n",
        "      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "      loss = outputs.loss\n",
        "      logits = outputs.logits\n",
        "\n",
        "      total_train_loss += loss.item()\n",
        "\n",
        "      # Clear the previously calculated gradient\n",
        "      model.zero_grad()     \n",
        "\n",
        "      # Perform a backward pass to calculate the gradients.\n",
        "      loss.backward()\n",
        "\n",
        "      # Update parameters and take a step using the computed gradient.\n",
        "      optimizer.step()\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set. Implement this function in the cell above.\n",
        "    print(f\"Total loss: {total_train_loss}\")\n",
        "    val_acc = get_validation_performance(val_set)\n",
        "    print(f\"Validation accuracy: {val_acc}\")\n",
        "    \n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2UQF_lZXafC",
        "outputId": "0ce09bbe-8dc0-4a82-ab21-781d386a5eb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of correct predictions = 751\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8534090909090909"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_validation_performance(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTdq34iL7ieq",
        "outputId": "d1ac30fa-d492-46ab-ab44-f90498b926f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  గత 15 సంవత్సరాలుగా ఆర్లింగ్టన్ కౌంటీ బోర్డ్ సభ్యుడిగా ఉన్న ఫిసెట్ (D) వివాహం చేసుకున్నారు.\n",
            "Token IDs: tensor([   101,   1203,  15125,  10208,   1233,  13652,  18892,  49184,  61924,\n",
            "         55558,  12540,   1189,  15695,  29652,  30164, 107543,   1201, 111341,\n",
            "         13652,  37551,   1222,  21120,  15695,  24487,   1233,  86149,  55632,\n",
            "         15697,  22012,  12540,  18732,   1221,  15868,  61924,  78820,    113,\n",
            "           141,    114, 105952,  18892,  15735,  65394,   1205,  17729,  39179,\n",
            "        110453,    119,    102,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0])\n"
          ]
        }
      ],
      "source": [
        "from helpers import tokenize_and_format, flat_accuracy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "df_json = pd.read_json('HW2_unlabeled_test_set.json')\n",
        "\n",
        "\n",
        "texts_json = df_json.sentence\n",
        "\n",
        "\n",
        "### tokenize_and_format() is a helper function provided in helpers.py ###\n",
        "input_ids_json, attention_masks_json = tokenize_and_format(texts_json)\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids_json = torch.cat(input_ids_json, dim=0)\n",
        "attention_masks_json = torch.cat(attention_masks_json, dim=0)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', texts_json[0])\n",
        "print('Token IDs:', input_ids_json[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "r-qEA1jRIDf9"
      },
      "outputs": [],
      "source": [
        "for i in range(len(texts_json)):\n",
        "    test_set = [(input_ids_json[i], attention_masks_json[i])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "P5UWNofN6yNq"
      },
      "outputs": [],
      "source": [
        "# function to get validation accuracy\n",
        "def get_pred(val_set):\n",
        "\n",
        "    # Put the model in evaluation mode\n",
        "    model.eval()\n",
        "    temp = np.array([])\n",
        "\n",
        "    num_batches = int(len(val_set)/batch_size) + 1\n",
        "\n",
        "    for i in range(num_batches):\n",
        "      end_index = min(batch_size * (i+1), len(val_set))\n",
        "      batch = val_set[i*batch_size:end_index]\n",
        "      \n",
        "      if len(batch) == 0: continue\n",
        "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
        "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
        "      \n",
        "      # Move tensors to the GPU\n",
        "      b_input_ids = input_id_tensors.to(device)\n",
        "      b_input_mask = input_mask_tensors.to(device)\n",
        "      \n",
        "      with torch.no_grad():  \n",
        "        # Forward pass, calculate logit predictions.      \n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = (logits).detach().cpu().numpy()\n",
        "        \n",
        "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "\n",
        "        temp = np.concatenate((temp, pred_flat))\n",
        "    return temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "0aKwK0mmIWdZ"
      },
      "outputs": [],
      "source": [
        "df_json.label_ID = get_pred(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "QRvxxcwFfEIH"
      },
      "outputs": [],
      "source": [
        "df_json.label_ID = df_json.label_ID + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "51x5kzVfR9we"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('labelname_to_ID.json') as code_file:\n",
        "    codes = json.load(code_file)\n",
        "    for label in df_json.label_ID:\n",
        "        df_json.predicted_label = [codes[str(label)]]\n",
        "\n",
        "df_json.to_json(\"FINAL_2.json\", orient = \"records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYEPw4y1fRlS",
        "outputId": "e0113396-22f7-4aab-f661-365d41abebb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          id                                           sentence  \\\n",
            "0          1  గత 15 సంవత్సరాలుగా ఆర్లింగ్టన్ కౌంటీ బోర్డ్ సభ...   \n",
            "1          2  Soll illegalen Einwanderern der Führerschein v...   \n",
            "2          3  由 D-San Francisco 议员 Mark Leno 赞助。大会司法委员会于 4 月...   \n",
            "3          4  एक वरिष्ठ प्रशासनिक अधिकारीले भने कि रेनो घोषण...   \n",
            "4          5  The panel Wednesday approved the resolution in...   \n",
            "...      ...                                                ...   \n",
            "38095  38096  Am Montag kam eine Gruppe prominenter Republik...   \n",
            "38096  38097  Haridopolos, R-Merritt Island, had pledged tha...   \n",
            "38097  38098  आईआरएस सूट ने गे मैरिज एक्टिविस्ट का सामना किय...   \n",
            "38098  38099                            BAM OUT 在权利的左边领域，说 POLS   \n",
            "38099  38100  Прокуратура сняла это обвинение, и шериф Сан-Ф...   \n",
            "\n",
            "                                 predicted_label  label_ID language  \n",
            "0                                      Political      13.0       te  \n",
            "1                          Fairness and Equality       4.0       de  \n",
            "2                                      Political      13.0    zh-CN  \n",
            "3                               Public Sentiment      12.0       ne  \n",
            "4                                      Political      13.0       en  \n",
            "...                                          ...       ...      ...  \n",
            "38095                                  Political      13.0       de  \n",
            "38096                                  Political      13.0       en  \n",
            "38097                      Fairness and Equality       4.0       hi  \n",
            "38098                     Capacity and Resources       2.0    zh-CN  \n",
            "38099  Legality, Constitutionality, Jurisdiction       5.0       ru  \n",
            "\n",
            "[38100 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df_json)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c094979aead45f3acda2595d9a745b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cef12bd5ed444c380f80d97bf15a68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5240221b374a47628589d3cdde2988c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7016fc81f71465c9bec034b92d7c47c",
            "placeholder": "​",
            "style": "IPY_MODEL_d6b42b4abb8a441a96dc83e73290ee29",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "6b4ba6c7258c4371b08448c81f0b6806": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_879c332a35f64d5588f6810fbb82e07b",
            "placeholder": "​",
            "style": "IPY_MODEL_0c094979aead45f3acda2595d9a745b6",
            "value": " 714M/714M [00:07&lt;00:00, 92.0MB/s]"
          }
        },
        "7abd44b1bafd4c1eb1be8fd628da4af6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "879c332a35f64d5588f6810fbb82e07b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6b42b4abb8a441a96dc83e73290ee29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2fabe4c6911416db1b121db636f9554": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7abd44b1bafd4c1eb1be8fd628da4af6",
            "max": 714314041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cef12bd5ed444c380f80d97bf15a68c",
            "value": 714314041
          }
        },
        "e7016fc81f71465c9bec034b92d7c47c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e880b864a58943aa9450851a587ee20e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec524b38bc594ab0a179bf29ef1f174e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5240221b374a47628589d3cdde2988c3",
              "IPY_MODEL_e2fabe4c6911416db1b121db636f9554",
              "IPY_MODEL_6b4ba6c7258c4371b08448c81f0b6806"
            ],
            "layout": "IPY_MODEL_e880b864a58943aa9450851a587ee20e"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
